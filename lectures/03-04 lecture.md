28/02/2025

# Дополнение по первой работе

Блок внутри parallel, выполняется один раз одним потоком. В отличие от critical, который исполняетяс всеми тредами но никогда одновременно, этот всего один раз

```c++
#pragma omp single
```

Нужен для того, чтобы выполнять одну задачу из того же потока (?)

```c++
#pragma omp masster
```

Есть еще omp task -- еще больший блок

```c++

```

# Вторая работа

Вручную с помощью конструкций C++ реализовать то, что делает OpenMP. Для измерения времени все еще можно использовать OMP время.
Поскольку разрезать цикл на части можно по-разному, то надо грамотно выбрать верный подход (dynamic scheduling?)

Ожидается ~такое же время исполнения

У OpenMP внутри thread pool. Потворять его не требуется
OpenMP не создает треды по каждому чиху;
После завершения работы он не убивает треды, а откладывает их на будущее

## Микро-история

Потоки использовались задолго ди их признания в стандарте C++11. Тогда использовался OpenMP, PThreads

## Операции

Подсчет тредов в C++

```C++
unsigned int num_threads = std::thread::hardware_concurrency();
```

Можно реализовать один общий параллелльный блок, посреди которого есть область исполняемая одним тредов (но нужн обыть увренным, что все треды перед началом области дойдут до этого места, т.е. нужны барьеры)

Барьер в МП -- место сбора для тредов, до которог овсе треды должны дойти перед тем как пойти дальше. OpenMP делает это в конце области Parallel

Для создания треда используем
```C++
std::thread
```
Может быть лямбдой (можно втянуть данные вокруг для лямбды (capture) -- становится проще работать)

    Если у нас 8 ядер, то мы создаем 7 новых, так как есть изначальный поток (не смотрим на число потоков -- там только 20%-30% прирост, так как потоки логические)
    Четырех-ядерный процессор с гипертредингом похож на обычный 5 ядер

> Множество потоков (2x к числу ядер) суперскалярностью современных процесорров -- ядро может исполнть несколько команд из разных блоков одновременно, если input и output не завивист от прочих условий.
> Из-за гипертрединга может быть небольшая потеря производетельности. 
> Кроме того, важен тот факт, что на оба потока все равн оодин кэш


Заметка по третьей работе:
Надо понимать, что существуют не только вычислительные блоки. То есть пределом производительности может оказаться не вычислительная мощность, а пропускная способность RAM.

На современных процах Intel есть жирные и тощие ядра, поэтому есть проблема для планировщика в распределении задач. В частности, заметно в компьютерных играх -- производительность може тв полтораза упасть. Чтобы решить проблему можно использовать affinity -- требовать исполнения на конкретных ядрах -- но тут проблема с универсальностью оптимизаии (она не возможна, нет классификации ядер)

    В лабе есть кусочек, где можно было бы использовать потоки на одном ядре

Атомарные операции есть и в C++. Правда она отличается от принципа OpenMP -- беру блок кода и делаю атомарным. Вместо этого тут есть атомарные типы, например int. Тогда все операции над этип типом будут атомарные (например, инкримент)

```C++
std::atomic
```

Ожидание тредов -- мысль "тред дошедший до какого-то момента остановился и поддождал, пока все остальгые дойдут сюда"
```C++
std::latch
```

Мьютекс -- как критические секции, описывающие, что не более один тред может войти в одну область. При этом это не критические секции, а объекты, захватываемые максимум одним потоком на исполнение

```C++
std::mutex
```

# Третья работа и четвертая 

Будет существенно отличаться, так как CUDA, массовый параллелизм
В четвертой больше страданий, но код будет работать на значительно большем числе устройств